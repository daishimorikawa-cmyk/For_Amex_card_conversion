import streamlit as st
import os
import pandas as pd
import importlib.util
import time
import json
import datetime
from processor import AmexProcessor
import pytesseract
from dotenv import load_dotenv

load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide", page_title="Amexæ˜ç´°å¤‰æ›ãƒ„ãƒ¼ãƒ«")


st.title("ğŸ’³ Amexåˆ©ç”¨æ˜ç´° PDFå¤‰æ›ãƒ„ãƒ¼ãƒ«")
st.markdown("""
PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€çµŒè²»ç²¾ç®—ç”¨CSV/TSVã‚’ä½œæˆã—ã¾ã™ã€‚
**ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å³å®ˆ**: å€‹äººæƒ…å ±ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒã‚¹ã‚­ãƒ³ã‚°ã•ã‚Œã€AIã«ã¯æ¸¡ã•ã‚Œã¾ã›ã‚“ã€‚
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("è¨­å®š")
    env_api_key = os.getenv("GEMINI_API_KEY", "")
    api_key_input = st.text_input("Gemini API Key", value=env_api_key, type="password")
    
    st.markdown("---")
    st.markdown("### ä¾å­˜ãƒ„ãƒ¼ãƒ«ãƒ‘ã‚¹è¨­å®š")
    
    # Defaults
    default_tesseract = os.getenv("TESSERACT_CMD", r"C:\Program Files\Tesseract-OCR\tesseract.exe")
    default_poppler = os.getenv("POPPLER_PATH", r"C:\poppler-25.12.0\Library\bin")
    
    tesseract_cmd = st.text_input("Tesseract Path", value=default_tesseract)
    poppler_path = st.text_input("Poppler Bin Path", value=default_poppler)
    
    st.markdown("---")
    st.markdown("### ä¾å­˜ãƒ„ãƒ¼ãƒ«çŠ¶æ…‹")
    
    # Check Poppler (mock check by ensuring path exists or fallback to import check)
    is_poppler_ok = os.path.exists(poppler_path) or (importlib.util.find_spec("pdf2image") is not None)
    st.write(f"Poppler Path: {'âœ… Found' if os.path.exists(poppler_path) else 'âš ï¸ Not Found (Check Path)'}")
    
    # Check Tesseract
    try:
        pytesseract.pytesseract.tesseract_cmd = tesseract_cmd
        tesseract_version = pytesseract.get_tesseract_version()
        st.write(f"Tesseract: âœ… v{tesseract_version}")
    except Exception:
        st.write("Tesseract: âŒ Error")
        st.error("Tesseractã®ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if not api_key_input:
    st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
processor = AmexProcessor(api_key_input, tesseract_cmd, poppler_path)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("Amexæ˜ç´°PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])

if uploaded_file is not None:
    if st.button("å¤‰æ›é–‹å§‹"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # 1. ç”»åƒåŒ–
            status_text.text("PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")
            pdf_bytes = uploaded_file.read()
            images = processor.convert_pdf_to_images(pdf_bytes)
            
            if len(images) < 2:
                st.error("ãƒšãƒ¼ã‚¸æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆ2ãƒšãƒ¼ã‚¸ä»¥ä¸Šå¿…è¦ã§ã™ï¼‰ã€‚")
                st.stop()
                
            total_pages = len(images)
            st.info(f"å…¨ {total_pages} ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            
            # 2. æœŸé–“æŠ½å‡º (Page 1)
            status_text.text("1ãƒšãƒ¼ã‚¸ç›®ã‹ã‚‰æœŸé–“ã‚’æŠ½å‡ºä¸­...")
            period_info = None
            try:
                period_info = processor.extract_period(images[0])
            except Exception as e:
                st.warning(f"æœŸé–“æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            
            if period_info:
                s = period_info['start']
                e_date = period_info['end']
                st.success(f"ğŸ“… æ˜ç´°å¯¾è±¡æœŸé–“: {s.strftime('%Y/%m/%d')} ã€œ {e_date.strftime('%Y/%m/%d')}")
            else:
                st.warning("âš ï¸ æœŸé–“ã®è‡ªå‹•æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¹´è£œå®Œã¯è¡Œã‚ã‚Œã¾ã›ã‚“ï¼ˆOCRã®æ—¥ä»˜ãã®ã¾ã¾ã¨ãªã‚Šã¾ã™ï¼‰ã€‚å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§CSVã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
                # period_info remains None, logic downstream must handle this.
            
            # 3. å„ãƒšãƒ¼ã‚¸å‡¦ç†
            all_transactions = []
            
            # Page 1 is skipped for transactions
            for i, img in enumerate(images[1:], start=2):
                status_text.text(f"Processing page {i}/{total_pages}...")
                progress = (i / total_pages)
                progress_bar.progress(progress)
                
                # Find Best Crop (Optical analysis)
                # "1/17 Amazon" å¯¾ç­–: æœ€é©ãªã‚¯ãƒ­ãƒƒãƒ—ç‡ã‚’è‡ªå‹•åˆ¤å®š
                best_crop_img = processor.find_best_crop(img)
                
                # LLM Extraction (Image -> JSON)
                # æ—¥æœ¬èªGarbageå¯¾ç­–: ç”»åƒã‚’ç›´æ¥Geminiã«æ¸¡ã—ã¦æ§‹é€ åŒ–æŠ½å‡º
                llm_response = processor.process_page_with_llm(best_crop_img)
                
                transactions = processor.parse_llm_response(
                    llm_response, 
                    period_info['start'] if period_info else None, 
                    period_info['end'] if period_info else None
                )
                
                if transactions:
                    st.write(f"Page {i}: {len(transactions)} ä»¶æŠ½å‡º")
                    all_transactions.extend(transactions)
                else:
                    st.warning(f"Page {i}: ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãªã— (ç©ºãƒšãƒ¼ã‚¸ã¾ãŸã¯èª­ã¿å–ã‚Šä¸èƒ½)")
                    # Debug: Show crop used
                    # st.image(best_crop_img, caption=f"Page {i} Crop Used", width=300)

            progress_bar.progress(1.0)
            status_text.text("å®Œäº†ï¼")
            
            if not all_transactions:
                st.error("æœ‰åŠ¹ãªæ˜ç´°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                # 4. DataFrameåŒ– & å‡ºåŠ›
                df = pd.DataFrame(all_transactions)
                
                # å¿…é ˆä»•æ§˜: 3åˆ— (Date, Description, Amount)
                # ç©ºæ¬„ Description ã¯ parse_llm_response ã§ "" ã«ãªã£ã¦ã„ã‚‹
                
                # Sort by date just in case
                try:
                    df['date_obj'] = pd.to_datetime(df['date'], errors='coerce')
                    df = df.sort_values('date_obj').drop(columns=['date_obj'])
                except:
                    pass

                final_cols = ["date", "description", "amount"]
                # Ensure columns exist
                for c in final_cols:
                    if c not in df.columns:
                        df[c] = ""
                        
                final_df = df[final_cols]
                
                # Check for empty descriptions (Logging requirement)
                empty_count = len(final_df[final_df['description'] == ""])
                if empty_count > 0:
                    st.warning(f"âš ï¸ {empty_count} ä»¶ã®æ˜ç´°ã§ã€Œæ”¯æ‰•ç›¸æ‰‹å…ˆã€ãŒç©ºæ¬„ã€ã¾ãŸã¯èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

                st.subheader("æŠ½å‡ºçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(final_df)
                
                # TSV Output (Headerãªã—)
                tsv = final_df.to_csv(sep="\t", index=False, header=False)
                st.text_area("TSVå‡ºåŠ› (ã‚³ãƒ”ãƒ¼ç”¨)", tsv, height=200)
                
                # CSV Download (Headerãªã—, UTF-8 BOMä»˜ã for Excel)
                csv = final_df.to_csv(index=False, header=False).encode('utf-8-sig')
                st.download_button(
                    label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Excelå¯¾å¿œ/UTF-8 BOM)",
                    data=csv,
                    file_name="amex_statement.csv",
                    mime="text/csv",
                )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.error("Popplerã‚„Tesseractã®è¨­å®šãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

